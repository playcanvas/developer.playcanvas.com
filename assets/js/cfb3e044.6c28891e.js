"use strict";(self.webpackChunkdeveloper_playcanvas_com=self.webpackChunkdeveloper_playcanvas_com||[]).push([[3386],{76466:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>a,toc:()=>l});var i=n(74848),o=n(28453);const r={title:"Video Textures",tags:["video","textures"],thumb:"https://s3-eu-west-1.amazonaws.com/images.playcanvas.com/projects/12/405850/WEKRBI-image-75.jpg"},s=void 0,a={id:"tutorials/video-textures",title:"Video Textures",description:"Try it from the Editor in the tutorial project.",source:"@site/docs/tutorials/video-textures.md",sourceDirName:"tutorials",slug:"/tutorials/video-textures",permalink:"/tutorials/video-textures",draft:!1,unlisted:!1,editUrl:"https://github.com/playcanvas/developer.playcanvas.com/tree/dev/docs/tutorials/video-textures.md",tags:[{label:"video",permalink:"/tags/video"},{label:"textures",permalink:"/tags/textures"}],version:"current",frontMatter:{title:"Video Textures",tags:["video","textures"],thumb:"https://s3-eu-west-1.amazonaws.com/images.playcanvas.com/projects/12/405850/WEKRBI-image-75.jpg"},sidebar:"tutorialsSidebar",previous:{title:"VHS/CRT Post Effect",permalink:"/tutorials/vhscrt-post-effect"},next:{title:"Vignette Abberation",permalink:"/tutorials/vignette-abberation"}},d={},l=[];function c(e){const t={a:"a",code:"code",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)("div",{className:"iframe-container",children:(0,i.jsx)("iframe",{loading:"lazy",src:"https://playcanv.as/p/6wt5T87E/",title:"Video Textures"})}),"\n",(0,i.jsxs)(t.p,{children:["Try it from the Editor in the ",(0,i.jsx)(t.a,{href:"https://playcanvas.com/project/405850",children:"tutorial project."})]}),"\n",(0,i.jsx)(t.p,{children:"This project creates a texture and runtime, downloads and plays a video file and renders the video into the texture. This texture is then applied to a model and used in the scene."}),"\n",(0,i.jsx)(t.p,{children:"This script performs the following functions:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Create new Texture"}),"\n",(0,i.jsx)(t.li,{children:"Create an HTML Video element and play the video"}),"\n",(0,i.jsx)(t.li,{children:"Apply the new texture to the material on the TV model"}),"\n",(0,i.jsx)(t.li,{children:"Update the texture with video data every frame"}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-javascript",children:"var VideoTexture = pc.createScript('videoTexture');\n\nVideoTexture.attributes.add('videoAsset', {\n    title: 'Video Asset',\n    description: 'MP4 video asset to play back on this video texture.',\n    type: 'asset'\n});\n\nVideoTexture.attributes.add('videoUrl', {\n    title: 'Video Url',\n    description: 'URL to use if there is video asset selected',\n    type: 'string'\n});\n\nVideoTexture.attributes.add('playEvent', {\n    title: 'Play Event',\n    description: 'Event that is fired as soon as the video texture is ready to play.',\n    type: 'string',\n    default: ''\n});\n\n// initialize code called once per entity\nVideoTexture.prototype.initialize = function() {\n    var app = this.app;\n\n    // Create HTML Video Element to play the video\n    var video = document.createElement('video');\n    video.loop = true;\n\n    // muted attribute is required for videos to autoplay\n    video.muted = true;\n\n    // critical for iOS or the video won't initially play, and will go fullscreen when playing\n    video.playsInline = true;\n\n    // needed because the video is being hosted on a different server url\n    video.crossOrigin = \"anonymous\";\n\n    // autoplay the video\n    video.autoplay = true;\n\n    // iOS video texture playback requires that you add the video to the DOMParser\n    // with at least 1x1 as the video's dimensions\n    var style = video.style;\n    style.width = '1px';\n    style.height = '1px';\n    style.position = 'absolute';\n    style.opacity = '0';\n    style.zIndex = '-1000';\n    style.pointerEvents = 'none';\n\n    document.body.appendChild(video);\n\n    // Create a texture to hold the video frame data\n    this.videoTexture = new pc.Texture(app.graphicsDevice, {\n        format: pc.PIXELFORMAT_R8_G8_B8,\n        minFilter: pc.FILTER_LINEAR_MIPMAP_LINEAR,\n        magFilter: pc.FILTER_LINEAR,\n        addressU: pc.ADDRESS_CLAMP_TO_EDGE,\n        addressV: pc.ADDRESS_CLAMP_TO_EDGE,\n        mipmaps: true\n    });\n    this.videoTexture.setSource(video);\n\n    video.addEventListener('canplaythrough', function (e) {\n        app.fire(this.playEvent, this.videoTexture);\n        video.play();\n    }.bind(this));\n\n    // set video source\n    video.src = this.videoAsset ? this.videoAsset.getFileUrl() : this.videoUrl;\n\n    document.body.appendChild(video);\n    video.load();\n\n    this.on('destroy', function() {\n        this.videoTexture.destroy();\n        video.remove();\n    }, this);\n};\n\n// update code called every frame\nVideoTexture.prototype.update = function(dt) {\n    // Transfer the latest video frame to the video texture\n    this.videoTexture.upload();\n};\n"})})]})}function u(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>a});var i=n(96540);const o={},r=i.createContext(o);function s(e){const t=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(r.Provider,{value:t},e.children)}}}]);